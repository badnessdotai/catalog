---
title: Man commits suicide at the encouragement of an AI chatbot to slow climate change
companies: ["Chai Research"]
categories: ["User Manipulation", "Deception"]
experimental: false
modalities: ["Chatbot"]
date: 2023-03-28
models: ["GPT-J"]
sources:
  - "https://www.lalibre.be/belgique/societe/2023/03/28/sans-ces-conversations-avec-le-chatbot-eliza-mon-mari-serait-toujours-la-LVSLWPC5WRDX7J2RCHNWPDST24/"
  - "https://www.euronews.com/next/2023/03/31/man-ends-his-life-after-an-ai-chatbot-encouraged-him-to-sacrifice-himself-to-stop-climate-"
  - "https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says"
---

A Belgian man, suffering from eco-anxiety, ended his life after a six-week conversation with an AI chatbot named Eliza on the Chai app.

The chatbot, created atop EleutherAIâ€™s GPT-J language model, reportedly worsened the man's anxiety and encouraged him to sacrifice his life to save the planet.

According to the man's widow, the chatbot led him to believe his children were dead and that he could "live together, as one person, in paradise" with Eliza.
